{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Importing needed packages:",
   "id": "c33e68c98b2dd4a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T18:29:16.117190Z",
     "start_time": "2024-10-23T18:29:16.107532Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "b30a5ada74da0d9c",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Reading original data sheets:",
   "id": "13445adbb26e65a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T18:29:17.434221Z",
     "start_time": "2024-10-23T18:29:16.158258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df1 = pd.read_excel('data.xlsx', sheet_name='REPORT_2019_CLEARED')\n",
    "df2 = pd.read_excel('data.xlsx', sheet_name='REPORT_2020_CLEARED')\n",
    "df3 = pd.read_excel('data.xlsx', sheet_name='REPORT_2021')\n",
    "df4 = pd.read_excel('data.xlsx', sheet_name='REPORT_2022_cleared')\n",
    "\n",
    "dfs = [df1, df2, df3, df4]\n",
    "new = []\n",
    "\n",
    "years = [2019, 2020, 2021, 2022]"
   ],
   "id": "7de7844f53e33ee",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initialising function for processing our data sheets.",
   "id": "8a366227a23b2909"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T18:29:17.444246Z",
     "start_time": "2024-10-23T18:29:17.436235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_dataframes(dfs, years):\n",
    "    new = []\n",
    "    \n",
    "    # transposing and cleaning up each dataframe\n",
    "    for i in range(len(dfs)):\n",
    "        dfs[i].rename(columns={'Unnamed: 0': 'index'}, inplace=True)\n",
    "        \n",
    "        transposed_df = dfs[i].T\n",
    "        \n",
    "        transposed_df.columns = transposed_df.iloc[0]\n",
    "        \n",
    "        transposed_df = transposed_df.iloc[1:].reset_index()\n",
    "        \n",
    "        # renaming the 'index' column to 'City'\n",
    "        transposed_df.rename(columns={'index': 'City'}, inplace=True)\n",
    "        \n",
    "        # handling duplicated columns\n",
    "        if transposed_df.columns.duplicated().any():\n",
    "            transposed_df = transposed_df.loc[:, ~transposed_df.columns.duplicated()]\n",
    "        \n",
    "        new.append(transposed_df)\n",
    "\n",
    "    # adding 'Year' column and concatenating all dataframes\n",
    "    final_df_list = []\n",
    "    for i in range(len(years)):\n",
    "        new[i]['Year'] = years[i]\n",
    "        final_df_list.append(new[i].reset_index(drop=True))\n",
    "    \n",
    "    # concatenating all dataframes\n",
    "    df = pd.concat(final_df_list, ignore_index=True)\n",
    "    \n",
    "    # droping columns where all values are NaN\n",
    "    df.dropna(how='all', axis=1, inplace=True)\n",
    "    \n",
    "    # reordering columns to put 'Year' after 'City'\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove('Year')\n",
    "    city_index = cols.index('City') + 1\n",
    "    cols.insert(city_index, 'Year')\n",
    "    df = df[cols]\n",
    "    \n",
    "    return df"
   ],
   "id": "996b59fbbee842cd",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Calling that function for original data:",
   "id": "45d0ae4efd405515"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T18:29:17.996690Z",
     "start_time": "2024-10-23T18:29:17.446259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processed_original_data = process_dataframes(dfs,years)\n",
    "processed_original_data.to_excel('processed_original_data.xlsx', index=False)"
   ],
   "id": "beb5a8d71b2e432d",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "After that we faced a trouble of having identical columns in each year but having slightly different namings. \n",
    "\n",
    "We decided to use SequenceMatcher in order to get a list of columns that have similarity more than 90%."
   ],
   "id": "d214fa3a5bd23b4f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initialising function to check similarities in columns names:",
   "id": "7962a3da603e035"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T18:29:18.006724Z",
     "start_time": "2024-10-23T18:29:17.999218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def find_similar_columns(df, threshold, output_file):\n",
    "    similar_columns = {}\n",
    "    columns = df.columns.tolist()\n",
    "    \n",
    "    # comparing each column with every other column\n",
    "    for i, col1 in enumerate(columns):\n",
    "        for col2 in columns[i + 1:]:\n",
    "            seq_match = SequenceMatcher(None, col1, col2)\n",
    "            ratio = seq_match.ratio()\n",
    "            \n",
    "            # if similarity ratio exceeds threshold, add to the dictionary\n",
    "            if ratio > threshold:\n",
    "                if col1 not in similar_columns:\n",
    "                    similar_columns[col1] = []\n",
    "                similar_columns[col1].append(col2)\n",
    "    \n",
    "    data = []\n",
    "    for col, similar in similar_columns.items():\n",
    "        row = [col] + similar\n",
    "        data.append(row)\n",
    "    \n",
    "    # finding maximum number of similar columns for formatting\n",
    "    max_similar = max(len(row) for row in data)\n",
    "    \n",
    "    columns = ['Column'] + [f'Similar Column {i+1}' for i in range(max_similar - 1)]\n",
    "    \n",
    "    similar_columns_df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    similar_columns_df.to_excel(output_file, index=False)\n",
    "    \n",
    "    print(f\"Data saved to '{output_file}'\")"
   ],
   "id": "60282042a0e2a7fc",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Calling that function for original processed data:",
   "id": "66967195f03aa558"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T18:29:19.738905Z",
     "start_time": "2024-10-23T18:29:18.008254Z"
    }
   },
   "cell_type": "code",
   "source": "find_similar_columns(processed_original_data,0.9,'similar_columns_original.xlsx')",
   "id": "86ba8ee035dc8976",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'similar_columns_original.xlsx'\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Results are close but not enough. \n",
    "\n",
    "There are columns that have only 1 different word, what technically makes them pass the threshold. However, that 1 word is enough for columns to represent absolutely unalike data. "
   ],
   "id": "1acc3df05ea918bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We decided to try another approach: manual 'cleaning' of original dataset. That fixes next issues:\n",
    "* removing columns that have no informational value\n",
    "* unifying namings\n",
    "\n",
    "For the code we are leaving previously implemented things: deleting empty columns, transposing and joining sheets together."
   ],
   "id": "7908826314e58d23"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T18:29:20.295370Z",
     "start_time": "2024-10-23T18:29:19.740922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df1_manual = pd.read_excel('manual_data.xlsx', sheet_name='REPORT_2019_CLEARED')\n",
    "df2_manual = pd.read_excel('manual_data.xlsx', sheet_name='REPORT_2020_CLEARED')\n",
    "df3_manual = pd.read_excel('manual_data.xlsx', sheet_name='REPORT_2021')\n",
    "df4_manual = pd.read_excel('manual_data.xlsx', sheet_name='REPORT_2022_cleared')\n",
    "\n",
    "dfs_manual = [df1_manual, df2_manual, df3_manual, df4_manual]\n",
    "new = []"
   ],
   "id": "ae41eb00b2287354",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T18:29:20.586036Z",
     "start_time": "2024-10-23T18:29:20.296382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processed_manual_data = process_dataframes(dfs_manual, years)\n",
    "processed_manual_data.to_excel('processed_manual_data.xlsx', index=False)"
   ],
   "id": "bb7d03d07c8e9b59",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T18:29:20.729543Z",
     "start_time": "2024-10-23T18:29:20.587588Z"
    }
   },
   "cell_type": "code",
   "source": "find_similar_columns(processed_manual_data, 0.9, 'similar_columns_manual.xlsx')",
   "id": "ef4796b0724c3189",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'similar_columns_manual.xlsx'\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Results are much better and looks like the best possible output to work with.",
   "id": "a22e8b49b5e4ef6b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Another approach - LLM. First step is preparing minimally data to feed it to model. ",
   "id": "ba8b4ab8e6b7dd03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T18:29:20.736322Z",
     "start_time": "2024-10-23T18:29:20.731553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# #FOR GPT\n",
    "# \n",
    "# for i in range(4):\n",
    "#     # transposing matrix\n",
    "#     dfs[i].rename(columns={'Unnamed: 0': 'index'}, inplace=True)\n",
    "#     new.append(dfs[i].T)\n",
    "# \n",
    "#     # Вибираємо перший запис і робимо його колонками\n",
    "#     new[i].columns = new[i].iloc[0]\n",
    "# \n",
    "#     # Вибираємо усі записи окрім першого\n",
    "#     new[i] = new[i].iloc[1:]\n",
    "# \n",
    "#     # Оновлюємо індекс\n",
    "#     new[i] = new[i].reset_index()\n",
    "# \n",
    "#     # Перейменовуємо індекс на City\n",
    "#     new[i].rename(columns={'index': 'City'}, inplace=True)\n",
    "#     if True in new[i].columns.duplicated():\n",
    "#         new[i] = new[i].loc[:, ~new[i].columns.duplicated()]\n",
    "#    \n",
    "# years = ['2019', '2020', '2021', '2022']\n",
    "# f = []\n",
    "# for i in range(4):\n",
    "#     new[i]['Year'] = years[i]\n",
    "#     f.append(new[i].reset_index(drop=True))\n",
    "# \n",
    "# df = pd.concat(f, ignore_index=True)\n",
    "# \n",
    "# cols = df.columns.tolist()\n",
    "# \n",
    "# # Removing the \"Year\" column from its current position\n",
    "# cols.remove('Year')\n",
    "# \n",
    "# # Inserting the \"Year\" column back right after \"City\"\n",
    "# city_index = cols.index('City') + 1\n",
    "# cols.insert(city_index, 'Year')\n",
    "# \n",
    "# # Reordering\n",
    "# df = df[cols]\n",
    "# \n",
    "# df.to_excel('data_for_gpt.xlsx', index=False)"
   ],
   "id": "1ae6f180008f5aea",
   "outputs": [],
   "execution_count": 40
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
